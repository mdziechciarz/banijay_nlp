{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model with POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame columns: \n",
    "df = pd.read_csv('emotion_data_merged_4_POS_crf.csv')\n",
    "\n",
    "# Tokenize sentences\n",
    "sentence_tokenizer = Tokenizer()\n",
    "sentence_tokenizer.fit_on_texts(df['sentence'])\n",
    "X_sentences = sentence_tokenizer.texts_to_sequences(df['sentence'])\n",
    "X_sentences = pad_sequences(X_sentences, maxlen=100)  # Adjust maxlen as needed\n",
    "\n",
    "# Tokenize POS tags\n",
    "pos_tokenizer = Tokenizer()\n",
    "pos_tokenizer.fit_on_texts(df['POS_crf'])\n",
    "X_pos = pos_tokenizer.texts_to_sequences(df['POS_crf'])\n",
    "X_pos = pad_sequences(X_pos, maxlen=100)  # Ensure this matches the text sequence length\n",
    "\n",
    "# Encode labels\n",
    "y = pd.get_dummies(df['emotion']).values\n",
    "\n",
    "# Split the dataset\n",
    "X_sentences_train, X_sentences_test, X_pos_train, X_pos_test, y_train, y_test = train_test_split(X_sentences, X_pos, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sentence_input (InputLayer)    [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " pos_input (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 100, 128)     10559616    ['sentence_input[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 100, 64)      6059072     ['pos_input[0][0]']              \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           49408       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 32)           12416       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 96)           0           ['lstm[0][0]',                   \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            582         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,681,094\n",
      "Trainable params: 16,681,094\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define inputs\n",
    "sentence_input = Input(shape=(100,), dtype='int32', name='sentence_input')  # Adjust shape based on your data\n",
    "pos_input = Input(shape=(100,), dtype='int32', name='pos_input')  # Adjust shape as needed\n",
    "\n",
    "# Embeddings\n",
    "sentence_emb = Embedding(input_dim=len(sentence_tokenizer.word_index)+1, output_dim=128, input_length=100)(sentence_input)\n",
    "pos_emb = Embedding(input_dim=len(pos_tokenizer.word_index)+1, output_dim=64, input_length=100)(pos_input)\n",
    "\n",
    "# LSTM layers\n",
    "sentence_lstm = LSTM(64)(sentence_emb)\n",
    "pos_lstm = LSTM(32)(pos_emb)\n",
    "\n",
    "# Concatenate the outputs\n",
    "concatenated = concatenate([sentence_lstm, pos_lstm], axis=-1)\n",
    "\n",
    "# Add a classifier\n",
    "output = Dense(len(df['emotion'].unique()), activation='softmax')(concatenated)\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=[sentence_input, pos_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11979/11979 [==============================] - 477s 39ms/step - loss: 0.1811 - accuracy: 0.9380 - val_loss: 0.1095 - val_accuracy: 0.9620\n",
      "Epoch 2/10\n",
      "11979/11979 [==============================] - 462s 39ms/step - loss: 0.0851 - accuracy: 0.9708 - val_loss: 0.1036 - val_accuracy: 0.9650\n",
      "Epoch 3/10\n",
      "11979/11979 [==============================] - 450s 38ms/step - loss: 0.0593 - accuracy: 0.9799 - val_loss: 0.1134 - val_accuracy: 0.9640\n",
      "Epoch 4/10\n",
      "11979/11979 [==============================] - 459s 38ms/step - loss: 0.0423 - accuracy: 0.9856 - val_loss: 0.1205 - val_accuracy: 0.9638\n",
      "Epoch 5/10\n",
      "11979/11979 [==============================] - 458s 38ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.1342 - val_accuracy: 0.9635\n",
      "Epoch 6/10\n",
      "11979/11979 [==============================] - 450s 38ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.1545 - val_accuracy: 0.9627\n",
      "Epoch 7/10\n",
      "11979/11979 [==============================] - 456s 38ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.1662 - val_accuracy: 0.9621\n",
      "Epoch 8/10\n",
      "11979/11979 [==============================] - 460s 38ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.1857 - val_accuracy: 0.9628\n",
      "Epoch 9/10\n",
      "11979/11979 [==============================] - 458s 38ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.2092 - val_accuracy: 0.9606\n",
      "Epoch 10/10\n",
      "11979/11979 [==============================] - 599s 50ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.2123 - val_accuracy: 0.9616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c01f0a48e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_sentences_train, X_pos_train], y_train, batch_size=32, epochs=10, validation_data=([X_sentences_test, X_pos_test], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2995/2995 [==============================] - 62s 21ms/step - loss: 0.2123 - accuracy: 0.9616\n",
      "Test Loss: 0.2122635692358017\n",
      "Test Accuracy: 0.9616082906723022\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate([X_sentences_test, X_pos_test], y_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>POS_crf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Girls are happy when they get flowers</td>\n",
       "      <td>[('Girls', 'VB'), ('are', 'DT'), ('happy', 'JJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>His jaw dropped in disbelief when he saw the p...</td>\n",
       "      <td>[('His', 'NNP'), ('jaw', 'NN'), ('dropped', 'N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sometimes the ugly stench makes me wanna throw...</td>\n",
       "      <td>[('Sometimes', 'NNP'), ('the', 'NN'), ('ugly',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The foul odor from the garbage bin was disgust...</td>\n",
       "      <td>[('The', 'DT'), ('foul', 'JJ'), ('odor', 'NN')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I can’t believe it, they lost the game in the ...</td>\n",
       "      <td>[('I', 'PRP'), ('can’t', 'VBP'), ('believe', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence  \\\n",
       "0   0              Girls are happy when they get flowers   \n",
       "1   1  His jaw dropped in disbelief when he saw the p...   \n",
       "2   2  Sometimes the ugly stench makes me wanna throw...   \n",
       "3   3  The foul odor from the garbage bin was disgust...   \n",
       "4   4  I can’t believe it, they lost the game in the ...   \n",
       "\n",
       "                                             POS_crf  \n",
       "0  [('Girls', 'VB'), ('are', 'DT'), ('happy', 'JJ...  \n",
       "1  [('His', 'NNP'), ('jaw', 'NN'), ('dropped', 'N...  \n",
       "2  [('Sometimes', 'NNP'), ('the', 'NN'), ('ugly',...  \n",
       "3  [('The', 'DT'), ('foul', 'JJ'), ('odor', 'NN')...  \n",
       "4  [('I', 'PRP'), ('can’t', 'VBP'), ('believe', '...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "kaggle_df = pd.read_csv('kaggle_data_POS_crf.csv', sep= ',')\n",
    "kaggle_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the sentences and POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assuming sentence_tokenizer and pos_tokenizer were trained on the original dataset\n",
    "X_new_sentences = sentence_tokenizer.texts_to_sequences(kaggle_df['sentence'])\n",
    "X_new_sentences = pad_sequences(X_new_sentences, maxlen=100)\n",
    "\n",
    "X_new_pos = pos_tokenizer.texts_to_sequences(kaggle_df['POS_crf'])\n",
    "X_new_pos = pad_sequences(X_new_pos, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/45 [..............................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict([X_new_sentences, X_new_pos])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert predicted classes back to labels using the mapping from training\n",
    "unique_labels = df['emotion'].unique()  \n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "index_to_label = {index: label for label, index in label_to_index.items()}\n",
    "\n",
    "# Now use this mapping to convert predicted classes back to labels\n",
    "predicted_labels = [index_to_label[k] for k in predicted_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predicted_labels.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the IDs and predicted labels\n",
    "results_df = pd.DataFrame({\n",
    "    'id': kaggle_df['id'],  # Make sure 'id' is the correct column name in your dataset\n",
    "    'emotion': predicted_labels\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('LSTM_POS.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "anger        374\n",
       "surprise     288\n",
       "sadness      221\n",
       "fear         213\n",
       "happiness    176\n",
       "disgust      164\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('LSTM_POS_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
