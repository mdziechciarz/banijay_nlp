{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Conditional Random Fields for POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook content\n",
    "\n",
    "1. Reading the data\n",
    "2. Creating POS using NLTK library (labelled dataset)\n",
    "3. Preparing the data for training\n",
    "4. Training the Conditional Random Field (CRF)\n",
    "5. Applying POS predictions with CRF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pycrfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_32292\\3366693756.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sample = df.groupby('emotion').apply(lambda x: x.sample(n=sample_size, random_state=1)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel that im a selfish person never give you...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i realized as long as i feel this way i will n...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel grouchy and i feel heavy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel like i am slowly drowning and there is ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was just having to decide on go and enjoy ti...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>Against all odds, a forgotten melody managed t...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>Just when the lottery ticket thought find a tr...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>No one could foresee that the famous actor wou...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>Against all odds, the long-lost sibling manage...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>It was unheard of for a forgotten melody to pe...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence   emotion\n",
       "0      i feel that im a selfish person never give you...     anger\n",
       "1      i realized as long as i feel this way i will n...     anger\n",
       "2                        i feel grouchy and i feel heavy     anger\n",
       "3      i feel like i am slowly drowning and there is ...     anger\n",
       "4      i was just having to decide on go and enjoy ti...     anger\n",
       "...                                                  ...       ...\n",
       "34995  Against all odds, a forgotten melody managed t...  surprise\n",
       "34996  Just when the lottery ticket thought find a tr...  surprise\n",
       "34997  No one could foresee that the famous actor wou...  surprise\n",
       "34998  Against all odds, the long-lost sibling manage...  surprise\n",
       "34999  It was unheard of for a forgotten melody to pe...  surprise\n",
       "\n",
       "[35000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/emotion_data_merged_4.csv')\n",
    "\n",
    "# Check if every emotion category has at least 20 sentences\n",
    "min_count = df['emotion'].value_counts().min()\n",
    "sample_size = min(5000, min_count)\n",
    "\n",
    "# Sample 5000 sentences for each emotion\n",
    "df_sample = df.groupby('emotion').apply(lambda x: x.sample(n=sample_size, random_state=1)).reset_index(drop=True)\n",
    "\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating POS using NLTK library (labelled dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize a sentence and tag it with POS\n",
    "def extract_pos(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return pos_tag(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 35000/35000 [00:53<00:00, 648.85it/s] \n"
     ]
    }
   ],
   "source": [
    "# Apply the function to each sentence in the DataFrame\n",
    "df_sample['POS'] = df_sample['sentence'].progress_apply(extract_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel that im a selfish person never give you...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[(i, NN), (feel, VBP), (that, IN), (im, VBZ), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i realized as long as i feel this way i will n...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[(i, RB), (realized, VBN), (as, RB), (long, RB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel grouchy and i feel heavy</td>\n",
       "      <td>anger</td>\n",
       "      <td>[(i, NN), (feel, VBP), (grouchy, NN), (and, CC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel like i am slowly drowning and there is ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[(i, JJ), (feel, VBP), (like, IN), (i, NN), (a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was just having to decide on go and enjoy ti...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[(i, NN), (was, VBD), (just, RB), (having, VBG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>Against all odds, a forgotten melody managed t...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>[(Against, IN), (all, DT), (odds, NNS), (,, ,)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>Just when the lottery ticket thought find a tr...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>[(Just, RB), (when, WRB), (the, DT), (lottery,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>No one could foresee that the famous actor wou...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>[(No, DT), (one, NN), (could, MD), (foresee, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>Against all odds, the long-lost sibling manage...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>[(Against, IN), (all, DT), (odds, NNS), (,, ,)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>It was unheard of for a forgotten melody to pe...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>[(It, PRP), (was, VBD), (unheard, JJ), (of, IN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence   emotion  \\\n",
       "0      i feel that im a selfish person never give you...     anger   \n",
       "1      i realized as long as i feel this way i will n...     anger   \n",
       "2                        i feel grouchy and i feel heavy     anger   \n",
       "3      i feel like i am slowly drowning and there is ...     anger   \n",
       "4      i was just having to decide on go and enjoy ti...     anger   \n",
       "...                                                  ...       ...   \n",
       "34995  Against all odds, a forgotten melody managed t...  surprise   \n",
       "34996  Just when the lottery ticket thought find a tr...  surprise   \n",
       "34997  No one could foresee that the famous actor wou...  surprise   \n",
       "34998  Against all odds, the long-lost sibling manage...  surprise   \n",
       "34999  It was unheard of for a forgotten melody to pe...  surprise   \n",
       "\n",
       "                                                     POS  \n",
       "0      [(i, NN), (feel, VBP), (that, IN), (im, VBZ), ...  \n",
       "1      [(i, RB), (realized, VBN), (as, RB), (long, RB...  \n",
       "2      [(i, NN), (feel, VBP), (grouchy, NN), (and, CC...  \n",
       "3      [(i, JJ), (feel, VBP), (like, IN), (i, NN), (a...  \n",
       "4      [(i, NN), (was, VBD), (just, RB), (having, VBG...  \n",
       "...                                                  ...  \n",
       "34995  [(Against, IN), (all, DT), (odds, NNS), (,, ,)...  \n",
       "34996  [(Just, RB), (when, WRB), (the, DT), (lottery,...  \n",
       "34997  [(No, DT), (one, NN), (could, MD), (foresee, V...  \n",
       "34998  [(Against, IN), (all, DT), (odds, NNS), (,, ,)...  \n",
       "34999  [(It, PRP), (was, VBD), (unheard, JJ), (of, IN...  \n",
       "\n",
       "[35000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 'NN'), ('feel', 'VBP'), ('that', 'IN'), ('im', 'VBZ'), ('a', 'DT'), ('selfish', 'JJ'), ('person', 'NN'), ('never', 'RB'), ('give', 'VBP'), ('you', 'PRP'), ('space', 'NN'), ('at', 'IN'), ('all', 'DT')]\n"
     ]
    }
   ],
   "source": [
    "pos_lists = df_sample['POS'].tolist()\n",
    "\n",
    "print(pos_lists[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparing the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features for each word in a sentence\n",
    "def word_features(sentence, i):\n",
    "\tword = sentence[i][0]\n",
    "\tfeatures = {\n",
    "\n",
    "\t\t'word': word,\n",
    "\t\t'is_first': i == 0, # if the word is a first word\n",
    "\t\t'is_last': i == len(sentence) - 1, # if the word is a last word\n",
    "\t\t'is_capitalized': word[0].upper() == word[0],\n",
    "\t\t'is_all_caps': word.upper() == word,\t # word is in uppercase\n",
    "\t\t'is_all_lower': word.lower() == word,\t # word is in lowercase\n",
    "\n",
    "\t\t# Prefix of the word\n",
    "\t\t'prefix-1': word[0], \n",
    "\t\t'prefix-2': word[:2],\n",
    "\t\t'prefix-3': word[:3],\n",
    "\n",
    "\t\t# Suffix of the word\n",
    "\t\t'suffix-1': word[-1],\n",
    "\t\t'suffix-2': word[-2:],\n",
    "\t\t'suffix-3': word[-3:],\n",
    "\n",
    "\t\t# Extracting previous word\n",
    "\t\t'prev_word': '' if i == 0 else sentence[i-1][0],\n",
    "\n",
    "\t\t# Extracting next word\n",
    "\t\t'next_word': '' if i == len(sentence)-1 else sentence[i+1][0],\n",
    "\t\t'has_hyphen': '-' in word, # if word has hypen\n",
    "\t\t'is_numeric': word.isdigit(), # if word is in numeric\n",
    "\t\t'capitals_inside': word[1:].lower() != word[1:]\n",
    "\t}\n",
    "\n",
    "\treturn features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty lists to store the X and y values\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each sentence and extract features\n",
    "for sentence in pos_lists:\n",
    "\tX_sentence = []\n",
    "\ty_sentence = []\n",
    "\tfor i in range(len(sentence)):\n",
    "\t\tX_sentence.append(word_features(sentence, i))\n",
    "\t\ty_sentence.append(sentence[i][1])\n",
    "\tX.append(X_sentence)\n",
    "\ty.append(y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the Conditional Random Field (CRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a CRF model suing pysrfsuite\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for x, y in zip(X_train, y_train):\n",
    "\ttrainer.append(x, y)\n",
    "trainer.set_params({\n",
    "\t'c1': 1.0,\n",
    "\t'c2': 1e-3,\n",
    "\t'max_iterations': 50,\n",
    "\t'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "trainer.train('pos.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9384892059488542\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('pos.crfsuite')\n",
    "\n",
    "# Predicting the tags for each sentence in the test set\n",
    "y_pred = []\n",
    "for xseq in X_test:\n",
    "    y_pred.append(tagger.tag(xseq))\n",
    "\n",
    "# You can calculate overall accuracy like this:\n",
    "accuracy = metrics.flat_accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('You', 'CC'), ('are', 'DT'), ('a', 'DT'), ('beautiful', 'NN'), ('person', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Tag a new sentence\n",
    "sentence = 'You are a beautiful person'.split()\n",
    "features = [word_features(sentence, i) for i in range(len(sentence))]\n",
    "tags = tagger.tag(features)\n",
    "print(list(zip(sentence, tags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Applying the CRF model POS to my original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and predict POS for a single sentence\n",
    "def predict_pos(sentence):\n",
    "    # Tokenize the sentence - you might need nltk.word_tokenize or a similar function\n",
    "    tokens = sentence.split()  # Adjust this if you have a more complex tokenization step\n",
    "    \n",
    "    # Extract features for each token in the sentence\n",
    "    features = [word_features(tokens, i) for i in range(len(tokens))]\n",
    "    \n",
    "    # Use the CRF model to predict POS tags\n",
    "    tags = tagger.tag(features)\n",
    "    \n",
    "    # Return the list of (token, POS) tuples\n",
    "    return list(zip(tokens, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662394</th>\n",
       "      <td>Witnessing the destruction of a natural habita...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662395</th>\n",
       "      <td>The vulgar display of wealth amidst poverty wa...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662396</th>\n",
       "      <td>The disregard for personal space and boundarie...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662397</th>\n",
       "      <td>Their manipulation of others' emotions for per...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662398</th>\n",
       "      <td>The normalization of toxic behavior in the com...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479140 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence    emotion\n",
       "0       im feeling rather rotten so im not very ambiti...    sadness\n",
       "1               im updating my blog because i feel shitty    sadness\n",
       "2       i never make her separate from me because i do...    sadness\n",
       "3       i left with my bouquet of red and yellow tulip...  happiness\n",
       "4         i was feeling a little vain when i did this one    sadness\n",
       "...                                                   ...        ...\n",
       "662394  Witnessing the destruction of a natural habita...    disgust\n",
       "662395  The vulgar display of wealth amidst poverty wa...    disgust\n",
       "662396  The disregard for personal space and boundarie...    disgust\n",
       "662397  Their manipulation of others' emotions for per...    disgust\n",
       "662398  The normalization of toxic behavior in the com...    disgust\n",
       "\n",
       "[479140 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "\n",
    "df.drop(df[df['emotion'] == 'neutral'].index, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 479140/479140 [01:14<00:00, 6414.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the 'sentence' column of df_sample\n",
    "df['POS_crf'] = df['sentence'].progress_apply(predict_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>POS_crf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[(im, NN), (feeling, VBP), (rather, NN), (rott...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[(im, NN), (updating, VBP), (my, JJ), (blog, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[(i, NN), (never, VBP), (make, JJ), (her, NN),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[(i, NN), (left, VBP), (with, JJ), (my, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[(i, NN), (was, VBP), (feeling, IN), (a, DT), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662394</th>\n",
       "      <td>Witnessing the destruction of a natural habita...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>[(Witnessing, NNP), (the, NN), (destruction, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662395</th>\n",
       "      <td>The vulgar display of wealth amidst poverty wa...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>[(The, DT), (vulgar, NN), (display, NN), (of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662396</th>\n",
       "      <td>The disregard for personal space and boundarie...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>[(The, DT), (disregard, NN), (for, NN), (perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662397</th>\n",
       "      <td>Their manipulation of others' emotions for per...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>[(Their, DT), (manipulation, JJ), (of, NN), (o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662398</th>\n",
       "      <td>The normalization of toxic behavior in the com...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>[(The, DT), (normalization, JJ), (of, NN), (to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479140 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence    emotion  \\\n",
       "0       im feeling rather rotten so im not very ambiti...    sadness   \n",
       "1               im updating my blog because i feel shitty    sadness   \n",
       "2       i never make her separate from me because i do...    sadness   \n",
       "3       i left with my bouquet of red and yellow tulip...  happiness   \n",
       "4         i was feeling a little vain when i did this one    sadness   \n",
       "...                                                   ...        ...   \n",
       "662394  Witnessing the destruction of a natural habita...    disgust   \n",
       "662395  The vulgar display of wealth amidst poverty wa...    disgust   \n",
       "662396  The disregard for personal space and boundarie...    disgust   \n",
       "662397  Their manipulation of others' emotions for per...    disgust   \n",
       "662398  The normalization of toxic behavior in the com...    disgust   \n",
       "\n",
       "                                                  POS_crf  \n",
       "0       [(im, NN), (feeling, VBP), (rather, NN), (rott...  \n",
       "1       [(im, NN), (updating, VBP), (my, JJ), (blog, N...  \n",
       "2       [(i, NN), (never, VBP), (make, JJ), (her, NN),...  \n",
       "3       [(i, NN), (left, VBP), (with, JJ), (my, NN), (...  \n",
       "4       [(i, NN), (was, VBP), (feeling, IN), (a, DT), ...  \n",
       "...                                                   ...  \n",
       "662394  [(Witnessing, NNP), (the, NN), (destruction, N...  \n",
       "662395  [(The, DT), (vulgar, NN), (display, NN), (of, ...  \n",
       "662396  [(The, DT), (disregard, NN), (for, NN), (perso...  \n",
       "662397  [(Their, DT), (manipulation, JJ), (of, NN), (o...  \n",
       "662398  [(The, DT), (normalization, JJ), (of, NN), (to...  \n",
       "\n",
       "[479140 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/emotion_data_merged_4_POS_crf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 1436/1436 [00:00<00:00, 12271.64it/s]\n"
     ]
    }
   ],
   "source": [
    "kaggle_base = pd.read_csv(\"data/kaggle_data.csv\", sep=\"\\t\")\n",
    "\n",
    "# Apply the function to the 'sentence' column of df_sample\n",
    "kaggle_base['POS_crf'] = kaggle_base['sentence'].progress_apply(predict_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_base.to_csv('data/kaggle_data_POS_crf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block_c_y2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
